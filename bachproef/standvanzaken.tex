\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz.\ naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin (narratieve referentie), gebruik je \texttt{$\backslash${}textcite\{\}}. Soms is de auteursnaam niet expliciet een onderdeel van de zin, dan gebruik je \texttt{$\backslash${}autocite\{\}} (referentie tussen haakjes). Dit gebruik je bv.~bij een citaat, of om in het bijschrift van een overgenomen afbeelding, broncode, tabel, enz. te verwijzen naar de bron. In de volgende paragraaf een voorbeeld van elk.

\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

Let er ook op: het \texttt{cite}-commando voor de punt, dus binnen de zin. Je verwijst meteen naar een bron in de eerste zin die erop gebaseerd is, dus niet pas op het einde van een paragraaf.

\section{Natural Language Processing: Een Overzicht en Toepassingen}

\subsection{Definitie en Belang van NLP}

Natural Language Processing (NLP) is een cruciale subdiscipline binnen de kunstmatige intelligentie die zich bezighoudt met de interactie tussen computers en menselijke (natuurlijke) talen. Het stelt machines in staat om menselijke taal te begrijpen en interpreteren, wat essentieel is voor het efficiënt verwerken van grote hoeveelheden tekstuele en spraakgegevens. De ontwikkeling van NLP heeft de manier waarop machines menselijke taal analyseren fundamenteel veranderd, waardoor ze niet alleen tekst kunnen begrijpen maar, ook reageren in een manier die voorheen voorbehouden was aan menselijke interactie \autocite{Sanadi2022}

\subsection{Toepassingen van NLP}

De toepassingen van NLP zijn divers en invloedrijk in verschillende domeinen, van machine vertaling en sentimentanalyse tot stem gestuurde assistenten. Deze technologieën worden steeds vaker geïmplementeerd in apparaten en diensten die we dagelijks gebruiken, wat aantoont hoe diepgaand NLP de interactie tussen mens en machine heeft getransformeerd. Door de integratie van NLP in deze applicaties kunnen apparaten complexe menselijke commando's begrijpen en hierop reageren, wat de bruikbaarheid en toegankelijkheid van technologie verbetert \autocite{Feng2020}

\subsection{Privacyvoordelen van Lokale NLP}

Een belangrijke ontwikkeling binnen NLP is de implementatie van deze technologieën direct op lokale apparaten, zoals Android smartphones. Door NLP lokaal uit te voeren, kunnen gebruikers profiteren van de voordelen die bij taalverwerking komen, zonder hun gegevens naar externe servers te sturen. Dit biedt aanzienlijke privacyvoordelen, aangezien gevoelige informatie op het apparaat zelf wordt verwerkt en beheerd, waardoor het risico op datalekken en externe toegang tot persoonlijke gegevens wordt verminderd. Deze benadering is vooral belangrijk in toepassingen waarbij gevoelige gegevens worden verwerkt, zoals in medische, financiële of persoonlijke assistent-applicaties \autocite{Locke2021Natural}

\subsection{Conclusie}

De integratie van NLP in zowel dagelijkse als gespecialiseerde technologieën heeft aanzienlijke voordelen voor het begrijpen en verwerken van menselijke taal. Door deze systemen lokaal te implementeren, kunnen ontwikkelaars en eindgebruikers genieten van zowel functionele als privacy-voordelen, wat essentieel is in onze steeds meer verbonden en gegevensgevoelige wereld.

\section{AI-Modellen voor Mobiele Apparaten: Een Focus op BERT, DistilBERT en TinyBERT}

\subsection{Overzicht van Modellen}

Recente ontwikkelingen in AI-modellen hebben geleid tot aanzienlijke vooruitgang in natuurlijke taalverwerking (NLP). Modellen zoals BERT (Bidirectional Encoder Representations from Transformers) en zijn afgeleiden, DistilBERT en TinyBERT, spelen een cruciale rol. BERT-modellen zijn met name effectief in het begrijpen van de context van een woord binnen een zin, wat hen zeer geschikt maakt voor complexe NLP-taken. Echter, vanwege hun grootte en complexiteit, zijn deze modellen vaak niet direct geschikt voor gebruik op mobiele apparaten met beperkte bronnen. Om dit probleem aan te pakken, zijn DistilBERT en TinyBERT ontwikkeld als kleinere, efficiëntere versies die beter geschikt zijn voor mobiele toepassingen. TinyBERT, bijvoorbeeld, is speciaal ontworpen voor kennisdestillatie van Transformer-gebaseerde modellen, wat resulteert in een model dat aanzienlijk kleiner en sneller is dan zijn voorganger, zonder aanzienlijke compromissen in de prestaties \autocite{Jiao2019TinyBERT}

\subsection{Criteria voor Modelkeuze}

Bij het kiezen van een taalmodel voor mobiele apparaten zijn er enkele belangrijke criteria te overwegen, waaronder modelgrootte, nauwkeurigheid en de benodigde rekenkracht. Kleinere modellen zoals TinyBERT en DistilBERT zijn vaak de voorkeursopties omdat ze minder opslagruimte en verwerkingscapaciteit vereisen. Deze modellen behouden een aanzienlijke mate van nauwkeurigheid, terwijl ze aanzienlijk sneller en lichter zijn, wat essentieel is voor toepassingen op mobiele apparaten \autocite{Sun2020MobileBERT}

\subsection{Vergelijking van Modellen}

TinyBERT en DistilBERT bieden beide aanzienlijke voordelen ten opzichte van het oorspronkelijke BERT-model wat betreft inzetbaarheid op mobiele apparaten. TinyBERT, bijvoorbeeld, biedt vergelijkbare prestaties als BERT-Base maar met slechts 28\% van de parameters en 31\% van de inferentietijd. DistilBERT daarentegen behoudt ongeveer 97\% van de taalbegripscapaciteit van BERT, terwijl het 40\% kleiner is en 60\% sneller dan het originele BERT-model. Deze modellen illustreren hoe kennisdestillatie kan worden gebruikt om krachtige, doch lichte modellen te creëren die geschikt zijn voor gebruik in resource-beperkte omgevingen zoals mobiele apparaten \autocite{Sanh2019DistilBERT}


\subsection{ BERT, RobBERT, RobBERTje}

- **Inleiding tot BERT**: Uitleg van het BERT-model en zijn prestaties bij verschillende natuurlijke taaltaken.
- **RobBERT en RobBERTje**: Beschrijving van de Nederlandse varianten van BERT en hun optimalisaties.
- **Vergelijking van Distillatiearchitecturen**: Onderzoek naar de prestaties van verschillende RobBERTje-modellen, inclusief de invloed van distillatiecorpus en trainingsmethoden.
- **Bias en Efficiëntie**: Analyse van bias in de modellen en efficiëntievoordelen van gedistilleerde modellen voor mobiele implementaties.

\subsection{Privacy en Gegevensbescherming}

- **Belang van Privacy**: Waarom lokale verwerking belangrijk is voor privacy en gegevensbescherming.
- **Gevoelige Data Verwerking**: Best practices voor het omgaan met gevoelige gegevens, inclusief data-encryptie en veilige communicatieprotocollen.
- **Privacy-overwegingen**: Overwegingen en maatregelen om de privacy van gebruikers te waarborgen.

\subsection{Huidige Oplossingen en Beperkingen}

- **Bestaande Methoden**: Analyse van bestaande toepassingen en methoden voor het integreren van AI op mobiele apparaten.
- **Voor- en Nadelen**: Voor- en nadelen van huidige oplossingen, inclusief technische en gebruiksaspecten.

\subsection{Model Conversie en Optimalisatie}

- **Model Conversie**: Stappen voor het converteren van modellen naar formaten die compatibel zijn met mobiele apparaten (bijv. TensorFlow Lite, ONNX).
- **Optimalisatietechnieken**: Beschrijving van optimalisatietechnieken zoals kwantisering, snoeien, en clustering om modelgrootte en inferentiesnelheid te verbeteren.

\subsection{Integratie van het Model in een Android Applicatie}

- **Mobiel-vriendelijke Deep Learning Frameworks**: Overzicht van frameworks zoals TensorFlow Lite en ONNX Runtime voor Android.
- **API's en Tools**: Beschikbare API's en tools voor modelimplementatie in Android-applicaties.
- **Preprocessing en Postprocessing**: Methoden voor data preprocessing, model inferentie, en output postprocessing.
- **Prestaties en Batterijoptimalisatie**: Technieken voor prestatie- en batterijoptimalisatie, zoals caching, achtergrondverwerking, en efficiënt geheugenbeheer.

\subsection{Soorten Android-diensten}

- **Android Input Method Editor (IME)**:
- **Voordelen en Nadelen**: Voor- en nadelen van het ontwikkelen van een IME voor tekstinvoer en taalmodelintegratie.
- **Implementatiestappen**: Stappen voor het opzetten en integreren van een IME.
- **Android System-level Service**:
- **Voordelen en Nadelen**: Voor- en nadelen van het ontwikkelen van een systeemdienst voor taalmodelgebaseerde functies.
- **Implementatiestappen**: Stappen voor het opzetten en integreren van een systeemdienst.

\subsection{Case Studies en Voorbeelden}

- **Relevante Voorbeelden**: Analyse van bestaande mobiele applicaties die AI-modellen lokaal draaien, inclusief succesverhalen en mislukkingen.
- **Lessons Learned**: Belangrijke lessen die getrokken kunnen worden uit bestaande case studies.
