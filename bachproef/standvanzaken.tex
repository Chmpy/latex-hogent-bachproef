\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz.\ naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin (narratieve referentie), gebruik je \texttt{$\backslash${}textcite\{\}}. Soms is de auteursnaam niet expliciet een onderdeel van de zin, dan gebruik je \texttt{$\backslash${}autocite\{\}} (referentie tussen haakjes). Dit gebruik je bv.~bij een citaat, of om in het bijschrift van een overgenomen afbeelding, broncode, tabel, enz. te verwijzen naar de bron. In de volgende paragraaf een voorbeeld van elk.

\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

Let er ook op: het \texttt{cite}-commando voor de punt, dus binnen de zin. Je verwijst meteen naar een bron in de eerste zin die erop gebaseerd is, dus niet pas op het einde van een paragraaf.

\section{Natural Language Processing: Een Overzicht en Toepassingen}

\subsection{Definitie en Belang van NLP}

Natural Language Processing (NLP) is een cruciale subdiscipline binnen de kunstmatige intelligentie die zich bezighoudt met de interactie tussen computers en menselijke (natuurlijke) talen. Het stelt machines in staat om menselijke taal te begrijpen en interpreteren, wat essentieel is voor het efficiënt verwerken van grote hoeveelheden tekstuele en spraakgegevens. De ontwikkeling van NLP heeft de manier waarop machines menselijke taal analyseren fundamenteel veranderd, w\-aar\-door ze niet alleen tekst kunnen begrijpen maar, ook reageren in een manier die voorheen voorbehouden was aan menselijke interactie \autocite{Sanadi2022}.

\subsection{Toepassingen van NLP}

De toepassingen van NLP zijn divers en invloedrijk in verschillende domeinen, van machine vertaling en sentimentanalyse tot stem gestuurde assistenten. Deze technologieën worden steeds vaker geïmplementeerd in apparaten en diensten die we dagelijks gebruiken, wat aantoont hoe diepgaand NLP de interactie tussen mens en machine heeft getransformeerd. Door de integratie van NLP in deze applicaties kunnen apparaten complexe menselijke commando's begrijpen en hierop reageren, wat de bruikbaarheid en toegankelijkheid van technologie verbetert \autocite{Feng2020}.

\subsection{Privacyvoordelen van Lokale NLP}

Een belangrijke ontwikkeling binnen NLP is de implementatie van deze technologieën direct op lokale apparaten, zoals Android smartphones. Door NLP lokaal uit te voeren, kunnen gebruikers profiteren van de voordelen die bij taalverwerking komen, zonder hun gegevens naar externe servers te sturen. Dit biedt aanzienlijke privacyvoordelen, aangezien gevoelige informatie op het apparaat zelf wordt verwerkt en beheerd, waardoor het risico op datalekken en externe toegang tot persoonlijke gegevens wordt verminderd. Deze benadering is vooral belangrijk in toepassingen waarbij gevoelige gegevens worden verwerkt, zoals in medische, financiële of persoonlijke assistent-applicaties \autocite{Locke2021Natural}.
\\ \\
De integratie van NLP in zowel dagelijkse als gespecialiseerde technologieën heeft aanzienlijke voordelen voor het begrijpen en verwerken van menselijke taal. Door deze systemen lokaal te implementeren, kunnen ontwikkelaars en eindgebruikers genieten van zowel functionele als privacy-voordelen, wat essentieel is in onze s\-t\-ee\-ds meer verbonden en gegevensgevoelige wereld.

\section{AI-Modellen voor Mobiele Apparaten: Een Focus op BERT, DistilBERT en TinyBERT}

\subsection{Overzicht van Modellen}

Recente ontwikkelingen in AI-modellen hebben geleid tot aanzienlijke vooruitgang in natuurlijke taalverwerking (NLP). Modellen zoals BERT (Bidirectional Encoder Representations from Transformers) en zijn afgeleiden, DistilBERT en TinyBERT, spelen een cruciale rol. BERT-modellen zijn met name effectief in het begrijpen van de context van een woord binnen een zin, wat hen zeer geschikt maakt voor complexe NLP-taken. Echter, vanwege hun grootte en complexiteit, zijn deze modellen vaak niet direct geschikt voor gebruik op mobiele apparaten met beperkte bronnen. Om dit probleem aan te pakken, zijn DistilBERT en TinyBERT ontwikkeld als kleinere, efficiëntere versies die beter geschikt zijn voor mobiele toepassingen. TinyBERT, bijvoorbeeld, is speciaal ontworpen voor kennisdestillatie van Transformer-gebaseerde modellen, wat resulteert in een model dat aanzienlijk kleiner en sneller is dan zijn voorganger, zonder aanzienlijke compromissen in de prestaties \autocite{Jiao2019TinyBERT}.

\subsection{Criteria voor Modelkeuze}

Bij het kiezen van een taalmodel voor mobiele apparaten zijn er enkele belangrijke criteria te overwegen, waaronder modelgrootte, nauwkeurigheid en de benodigde rekenkracht. Kleinere modellen zoals TinyBERT en DistilBERT zijn vaak de voorkeursopties omdat ze minder opslagruimte en verwerkingscapaciteit vereisen. Deze modellen behouden een aanzienlijke mate van nauwkeurigheid, terwijl ze aanzienlijk sneller en lichter zijn, wat essentieel is voor toepassingen op mobiele apparaten \autocite{Sun2020MobileBERT}.

\subsection{Vergelijking van Modellen}

TinyBERT en DistilBERT bieden beide aanzienlijke voordelen ten opzichte van het oorspronkelijke BERT-model wat betreft inzetbaarheid op mobiele apparaten. TinyBERT, bijvoorbeeld, biedt vergelijkbare prestaties als BERT-Base maar met slechts 28\% van de parameters en 31\% van de inferentietijd. DistilBERT daarentegen behoudt ongeveer 97\% van de taalbegripscapaciteit van BERT, terwijl het 40\% kleiner is en 60\% sneller dan het originele BERT-model. Deze modellen illustreren hoe kennisdestillatie kan worden gebruikt om krachtige, doch lichte modellen te creëren die geschikt zijn voor gebruik in resource-beperkte omgevingen zoals mobiele apparaten \autocite{Sanh2019DistilBERT}.


\section{BERT, RobBERT, en RobBERTje: Prestaties en Optimalisaties van Nederlandse Taalmodellen}

\subsection{Inleiding tot BERT}

BERT (Bidirectional Encoder Representations from Transformers) is een trans\-for\-mer-gebaseerd model dat heeft gezorgd voor aanzienlijke verbeteringen in verschillende natuurlijke taaltaken door zijn vermogen om diepe bidirectionele representaties te pre-trainen. Dit model kan fijn afgesteld worden met slechts één extra outputlaag om toonaangevende resultaten te leveren voor een breed scala aan taken, zoals vraag beantwoording en taal inferentie, zonder substantiële aanpassingen in de taakspecifieke architectuur \autocite{Devlin2019}.

\subsection{RobBERT en RobBERTje}

RobBERT en RobBERTje zijn Nederlandse varianten van het BERT-model, ontwikkeld om beter te presteren op taaltaken specifiek voor het Nederlands. RobBERT gebruikt een modelarchitectuur vergelijkbaar met die van BERT maar is getraind op een rijke dataset van Nederlandse teksten, wat resulteert in verbeterde prestaties op downstream NLP-taken zoals part-of-speech tagging en naamherkenning. RobBERTje is een verder gedistilleerde versie, gecreëerd met zicht op een efficiëntie in grote en snelheid voor mobiele toepassingen \autocite{Vries2019}.

\subsection{Vergelijking van Distillatiearchitecturen}

Distillatiearchitecturen zoals TinyBERT, DistilBERT en RobBERTje hebben elk unieke benaderingen en optimalisaties die hen onderscheiden, vooral in hoe ze presteren en hoe ze worden getraind.

\textbf{TinyBERT} maakt gebruik van een tweefasig leerproces dat zowel tijdens de pre-training als taakspecifieke afstemming plaatsvindt. Deze methode zorgt ervoor dat TinyBERT zowel algemene als taakspecifieke kennis efficiënt kan overnemen van zijn 'leraar'-model. TinyBERT slaagt erin om met slechts 28\% van de parameters en 31\% van de inferentietijd vergeleken met zijn leraar, BERT-Base, toch meer dan 96.8\% van de prestaties te behouden op de GLUE benchmark. Deze indrukwekkende reductie in grootte en snelheid maakt TinyBERT bijzonder geschikt voor mobiele en ingebedde toepassingen \autocite{Jiao2019TinyBERT}.

\textbf{DistilBERT}, aan de andere kant, is ontworpen om de grootte van het BERT-model met 40\% te verminderen, terwijl nog steeds 97\% van zijn taalbegripscapaciteiten behouden blijft. Dit wordt bereikt door kennisdestillatie toe te passen tijdens de pre-trainingsfase. DistilBERT gebruikt een 'triple loss' die taalmodellering, distillatie en cosinusafstandsverlies combineert, wat bijdraagt aan een efficiënte overdracht van kennis en een snellere inferentie, waardoor het een kosteneffectieve keuze is voor op apparaat gebaseerde berekeningen \autocite{Sanh2019DistilBERT}.

\textbf{RobBERTje} richt zich op het optimaliseren van de Nederlandse taalmodellen door verschillende distillatiecorpora te onderzoeken. Dit onderzoek heeft aangetoond dat het mengen van opeenvolgende zinnen in een corpus kan leiden tot modellen die sneller trainen en beter presteren op taken met lange sequenties. Dit suggereert dat de structuur van het trainingscorpus aanzienlijk kan bijdragen aan de effectiviteit van gedistilleerde modellen. Interessant is dat RobBERTje ook minder genderstereotype bias vertoont dan zijn leraarsmodel, wat wijst op een bijkomend voordeel van het distillatieproces \autocite{Delobelle2021}.

Deze diverse benaderingen van modeldistillatie illustreren de veelzijdigheid en aanpasbaarheid van distillatiearchitecturen in het verkleinen en versnellen van trans\-for\-mer-gebaseerde modellen, terwijl nog steeds een hoge mate van nauwkeurigheid behouden blijft. Elk van deze modellen biedt unieke voordelen, afhankelijk van de specifieke eisen en beperkingen van de toepassing, zoals geheugenbeperkingen, rekenkracht, en de specifieke kenmerken van de taak of het taaldomein.


\subsection{Bias en Efficiëntie}

Ondanks de efficiëntievoordelen van gedistilleerde modellen zoals RobBERTje, is het belangrijk om aandacht te besteden aan de bias die deze modellen kunnen bevatten. Het minimaliseren van bias terwijl de efficiëntie wordt gemaximaliseerd, blijft een belangrijk aandachtspunt voor de ontwikkeling van toekomstige NLP-modellen. Efficiëntie in training en inferentie is cruciaal voor de bruikbaarheid van deze modellen in real-world toepassingen, vooral op mobiele apparaten waar rekenkracht en geheugen beperkt zijn.


\section{Privacy en Gegevensbescherming}

\subsection{Belang van Privacy}

Lokale verwerking van gegevens wordt steeds belangrijker voor privacy en gegevensbescherming, vooral in het tijdperk van Internet der Dingen (IoT) en edge computing. Door gegevens lokaal te verwerken, wordt de noodzaak voor gegevensoverdracht over het netwerk verminderd, wat niet alleen de efficiëntie verbetert maar ook het risico op gegevenslekken vermindert. Dit is essentieel in situaties waar de privacy van gebruikers cruciaal is, zoals in gezondheidszorg en financiële diensten \autocite{Bi2020}.

\subsection{Gevoelige Data Verwerking}

Het beheren van gevoelige gegevens vereist een zorgvuldige aanpak om privacy van de gebruiker te waarborgen. Best practices omvatten het gebruik van data-encryptie en veilige communicatieprotocollen om te verzekeren dat gegevens tijdens de overdracht en opslag beschermd zijn. Technieken zoals de Advanced Encryption Standard (AES) en Secure Sockets Layer (SSL) zijn cruciaal voor het veilig overbrengen en opslaan van gegevens. Daarnaast is de implementatie van lokale differentiële privacytechnieken een effectieve manier om te zorgen voor anonimiteit van gegevens, terwijl de bruikbaarheid van ervan behouden blijft \autocite{Shah2014}.

\subsection{Privacy-overwegingen}

Bij het ontwerpen van systemen die gevoelige gegevens verwerken, moeten ontwikkelaars diverse privacy-overwegingen in acht nemen. Dit omvat het minimaliseren van gegevensverzameling, het verzekeren van transparantie over hoe gegevens worden gebruikt, en het implementeren van robuuste toegangscontrolesystemen. Het is ook belangrijk om privacy by design-principes te adopteren, wat betekent dat privacybescherming vanaf het begin geïntegreerd wordt bij het systeemontwerp. Methoden zoals het minimaliseren van de verzamelde gegevens en het verzekeren van een sterke gebruikerstoestemming voor het gebruik van hun gegevens zijn essentieel voor het handhaven van vertrouwen en integriteit in data gedreven systemen \autocite{Edwards2019}.


\section{Huidige Oplossingen en Beperkingen}

\subsection{Bestaande Methoden}

\textbf{Spraakherkenning op Mobiele Apparaten:}
Spraakherkenningstechnologie, aangedreven door AI, is aanzienlijk verbeterd en wordt gebruikt in diverse toepassingen zoals virtuele assistenten, spraak gestuurde apparaten en dicteer software. Deze technologie maakt gebruik van machine learning-algoritmen die getraind zijn op grote hoeveelheden spraakgegevens om menselijke spraak te herkennen en interpreteren met nauwkeurigheidsniveaus die vergelijkbaar zijn met die van mensen. Automatische spraakherkennings(ASR)-systemen bestaan uit drie hoofdcomponenten: het akoestische model, het taalmodel en de decoder. Deze componenten werken samen om gesproken input te verwerken in geschreven tekst, ondanks uitdagingen zoals spraakvariatie en achtergrondlawaai \autocite{Wang2023}.
\\ \\
\textbf{Beeldverwerking op Mobiele Apparaten:}
AI wordt ook uitgebreid toegepast in de beeldverwerking op mobiele apparaten, voornamelijk voor functies zoals gezichtsherkenning en objectdetectie. Deze systemen gebruiken diepe leermodellen die zijn geoptimaliseerd voor mobiele apparaten om complexe beeldverwerkingstaken uit te voeren. Door gebruik te maken van convolutionele neurale netwerken (CNN's) kunnen deze modellen patronen in visuele gegevens herkennen en interpreteren, wat van cruciaal belang is voor toepassingen zoals fotografie-apps, gezondheidsmonitoring en interactieve gaming \autocite{Luo2018}. Bovendien versterken geavanceerde AI-strategieën de mogelijkheden van mobiele applicaties door contextbewustzijn en adaptief leren te bieden, wat essentieel is voor gepersonaliseerde gebruikerservaringen \autocite{Sarker2021}.

\subsection{Voor- en Nadelen}

\textbf{Voordelen} van deze AI-toepassingen omvatten de mogelijkheid om complexe en natuurlijke interacties met apparaten te faciliteren, wat leidt tot een verbeterde gebruikerservaring. Door lokale verwerking kunnen deze toepassingen ook werken met minimale latency en verhoogde privacy voor de gebruiker.
\\ \\
\textbf{Nadelen} zijn onder meer de beperkingen in verwerkingskracht en batterijduur van mobiele apparaten, wat de complexiteit en efficiëntie van de uitvoerbare AI-modellen beperkt. Bovendien kunnen deze systemen te maken krijgen met uitdagingen zoals onnauwkeurigheden in moeilijke omgevingscondities en de noodzaak van continue updates om de modellen te verbeteren en adapteren aan nieuwe data \autocite{Castanyer2021}.


\section{Model Conversie en Optimalisatie}

\subsection{Model Conversie}

Het converteren van AI-modellen naar formaten die compatibel zijn met mobiele apparaten is een cruciale stap om de implementatie van machine learning in mobiele applicaties te faciliteren. Veelgebruikte formaten voor compatibiliteit omvatten TensorFlow Lite en ONNX (Open Neural Network Exchange). TensorFlow Lite is een lichtgewicht oplossing die speciaal is ontworpen voor mobiele en ingebedde apparaten, en biedt tools die modellen optimaliseren voor on-device uitvoering. ONNX daarentegen is een open formaat dat ontworpen is om modelportabiliteit en interoperabiliteit te ondersteunen, zodat ontwikkelaars modellen kunnen gebruiken over verschillende frameworks en tools heen zonder dat modelconversie nodig is. Dit proces omvat gewoonlijk het vereenvoudigen, verminderen van de grootte, en verzekeren dat het model efficiënt werkt binnen de beperkingen van een mobiel apparaat \autocite{Dalwadi2021}.

\subsection{Optimalisatietechnieken}

Naast conversie zijn geavanceerde optimalisatietechnieken essentieel om de prestaties van AI-modellen op mobiele apparaten te verbeteren. Deze omvatten:

\begin{enumerate}
    \item \textbf{Kwantisatie}: Dit proces converteert een model van drijvende-kommagetalindeling naar een gehele getallen indeling, wat de modelgrootte vermindert en de inferentie snelheid verhoogt zonder significante verlies van nauwkeurigheid. Verschillende vormen van kwantisatie, zoals uniforme en niet-uniforme, kunnen worden toegepast, afhankelijk van de specifieke vereisten van de toepassing \autocite{Wang2022}.
    
    \item \textbf{Snoeien}: Door onnodige, redundante of minder belangrijke gewichten uit het neurale netwerk te verwijderen, vermindert snoeien de complexiteit en grootte van het model, wat resulteert in snellere verwerkingstijden. Deze techniek kan zowel gestructureerd als ongestructureerd worden toegepast om verschillende niveaus van compressie te bereiken, afhankelijk van de doelstellingen met betrekking tot modelprestatie en -compressie.
    
    \item \textbf{Clustering}: Deze techniek groepeert de gewichten van het neurale netwerk in een beperkt aantal clusters om de algehele grootte van het model te verminderen en de inferentie snelheid te verhogen. Clustering kan worden gecombineerd met kwantisatie om verdere compressie en prestatieverbeteringen te bereiken \autocite{Ye2018}.
\end{enumerate}

Deze technieken dragen bij aan de efficiëntie van AI-modellen door het verminderen van hun rekenlast en geheugenvereisten, waardoor ze beter geschikt zijn voor gebruik op mobiele apparaten met beperkte resources.


\section{Integratie van het Model in een Android Applicatie}

- **Mobiel-vriendelijke Deep Learning Frameworks**: Overzicht van frameworks zoals TensorFlow Lite en ONNX Runtime voor Android.
- **API's en Tools**: Beschikbare API's en tools voor modelimplementatie in Android-applicaties.
- **Preprocessing en Postprocessing**: Methoden voor data preprocessing, model inferentie, en output postprocessing.
- **Prestaties en Batterijoptimalisatie**: Technieken voor prestatie- en batterijoptimalisatie, zoals caching, achtergrondverwerking, en efficiënt geheugenbeheer.

\section{Soorten Android-diensten}

- **Android Input Method Editor (IME)**:
- **Voordelen en Nadelen**: Voor- en nadelen van het ontwikkelen van een IME voor tekstinvoer en taalmodelintegratie.
- **Implementatiestappen**: Stappen voor het opzetten en integreren van een IME.
- **Android System-level Service**:
- **Voordelen en Nadelen**: Voor- en nadelen van het ontwikkelen van een systeemdienst voor taalmodelgebaseerde functies.
- **Implementatiestappen**: Stappen voor het opzetten en integreren van een systeemdienst.

\section{Case Studies en Voorbeelden}

- **Relevante Voorbeelden**: Analyse van bestaande mobiele applicaties die AI-modellen lokaal draaien, inclusief succesverhalen en mislukkingen.
- **Lessons Learned**: Belangrijke lessen die getrokken kunnen worden uit bestaande case studies.
